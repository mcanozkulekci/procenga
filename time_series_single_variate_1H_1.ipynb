{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UDXvd4uwhZjc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "TTD1DUEUlFrC",
    "outputId": "ddca7869-40e4-4e61-cd59-1aa63c600cad"
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unix</th>\n      <th>date</th>\n      <th>symbol</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>Volume BTC</th>\n      <th>Volume USDT</th>\n      <th>tradecount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.612915e+12</td>\n      <td>2021-02-10 00:00:00</td>\n      <td>BTC/USDT</td>\n      <td>46420.42</td>\n      <td>46557.24</td>\n      <td>46052.52</td>\n      <td>46207.49</td>\n      <td>639.739914</td>\n      <td>2.960948e+07</td>\n      <td>20978.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.612912e+12</td>\n      <td>2021-02-09 23:00:00</td>\n      <td>BTC/USDT</td>\n      <td>46839.99</td>\n      <td>46860.00</td>\n      <td>46201.37</td>\n      <td>46420.42</td>\n      <td>2790.416785</td>\n      <td>1.296341e+08</td>\n      <td>113106.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.612908e+12</td>\n      <td>2021-02-09 22:00:00</td>\n      <td>BTC/USDT</td>\n      <td>47241.92</td>\n      <td>47241.92</td>\n      <td>46440.52</td>\n      <td>46839.01</td>\n      <td>2914.614311</td>\n      <td>1.363150e+08</td>\n      <td>105273.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.612904e+12</td>\n      <td>2021-02-09 21:00:00</td>\n      <td>BTC/USDT</td>\n      <td>47084.16</td>\n      <td>47461.06</td>\n      <td>46995.92</td>\n      <td>47231.03</td>\n      <td>2564.524939</td>\n      <td>1.211090e+08</td>\n      <td>77433.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.612901e+12</td>\n      <td>2021-02-09 20:00:00</td>\n      <td>BTC/USDT</td>\n      <td>47060.38</td>\n      <td>47499.43</td>\n      <td>46668.48</td>\n      <td>47084.17</td>\n      <td>3254.702714</td>\n      <td>1.532251e+08</td>\n      <td>100788.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33184</th>\n      <td>1.502957e+09</td>\n      <td>2017-08-17 08-AM</td>\n      <td>BTC/USDT</td>\n      <td>4349.99</td>\n      <td>4377.85</td>\n      <td>4333.32</td>\n      <td>4360.69</td>\n      <td>0.949900</td>\n      <td>4.139700e+03</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>33185</th>\n      <td>1.502953e+09</td>\n      <td>2017-08-17 07-AM</td>\n      <td>BTC/USDT</td>\n      <td>4324.35</td>\n      <td>4349.99</td>\n      <td>4287.41</td>\n      <td>4349.99</td>\n      <td>4.440000</td>\n      <td>1.924106e+04</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>33186</th>\n      <td>1.502950e+09</td>\n      <td>2017-08-17 06-AM</td>\n      <td>BTC/USDT</td>\n      <td>4315.32</td>\n      <td>4345.45</td>\n      <td>4309.37</td>\n      <td>4324.35</td>\n      <td>7.230000</td>\n      <td>3.128231e+04</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>33187</th>\n      <td>1.502946e+09</td>\n      <td>2017-08-17 05-AM</td>\n      <td>BTC/USDT</td>\n      <td>4308.83</td>\n      <td>4328.69</td>\n      <td>4291.37</td>\n      <td>4315.32</td>\n      <td>23.230000</td>\n      <td>1.003048e+05</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>33188</th>\n      <td>1.502942e+09</td>\n      <td>2017-08-17 04-AM</td>\n      <td>BTC/USDT</td>\n      <td>16199.91</td>\n      <td>16199.91</td>\n      <td>4261.32</td>\n      <td>4308.83</td>\n      <td>44.510000</td>\n      <td>1.909529e+05</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>33189 rows × 10 columns</p>\n</div>",
      "text/plain": "               unix                 date    symbol      open      high  \\\n0      1.612915e+12  2021-02-10 00:00:00  BTC/USDT  46420.42  46557.24   \n1      1.612912e+12  2021-02-09 23:00:00  BTC/USDT  46839.99  46860.00   \n2      1.612908e+12  2021-02-09 22:00:00  BTC/USDT  47241.92  47241.92   \n3      1.612904e+12  2021-02-09 21:00:00  BTC/USDT  47084.16  47461.06   \n4      1.612901e+12  2021-02-09 20:00:00  BTC/USDT  47060.38  47499.43   \n...             ...                  ...       ...       ...       ...   \n33184  1.502957e+09     2017-08-17 08-AM  BTC/USDT   4349.99   4377.85   \n33185  1.502953e+09     2017-08-17 07-AM  BTC/USDT   4324.35   4349.99   \n33186  1.502950e+09     2017-08-17 06-AM  BTC/USDT   4315.32   4345.45   \n33187  1.502946e+09     2017-08-17 05-AM  BTC/USDT   4308.83   4328.69   \n33188  1.502942e+09     2017-08-17 04-AM  BTC/USDT  16199.91  16199.91   \n\n            low     close   Volume BTC   Volume USDT  tradecount  \n0      46052.52  46207.49   639.739914  2.960948e+07     20978.0  \n1      46201.37  46420.42  2790.416785  1.296341e+08    113106.0  \n2      46440.52  46839.01  2914.614311  1.363150e+08    105273.0  \n3      46995.92  47231.03  2564.524939  1.211090e+08     77433.0  \n4      46668.48  47084.17  3254.702714  1.532251e+08    100788.0  \n...         ...       ...          ...           ...         ...  \n33184   4333.32   4360.69     0.949900  4.139700e+03         NaN  \n33185   4287.41   4349.99     4.440000  1.924106e+04         NaN  \n33186   4309.37   4324.35     7.230000  3.128231e+04         NaN  \n33187   4291.37   4315.32    23.230000  1.003048e+05         NaN  \n33188   4261.32   4308.83    44.510000  1.909529e+05         NaN  \n\n[33189 rows x 10 columns]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_csv(\"Binance_BTCUSDT_1h.csv\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "R9KhXRQMlajh",
    "outputId": "5fe4b964-e266-4b69-fff7-1b91249bdf75"
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>46207.49</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>46420.42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>46839.01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>47231.03</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>47084.17</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33184</th>\n      <td>4360.69</td>\n    </tr>\n    <tr>\n      <th>33185</th>\n      <td>4349.99</td>\n    </tr>\n    <tr>\n      <th>33186</th>\n      <td>4324.35</td>\n    </tr>\n    <tr>\n      <th>33187</th>\n      <td>4315.32</td>\n    </tr>\n    <tr>\n      <th>33188</th>\n      <td>4308.83</td>\n    </tr>\n  </tbody>\n</table>\n<p>33189 rows × 1 columns</p>\n</div>",
      "text/plain": "          close\n0      46207.49\n1      46420.42\n2      46839.01\n3      47231.03\n4      47084.17\n...         ...\n33184   4360.69\n33185   4349.99\n33186   4324.35\n33187   4315.32\n33188   4308.83\n\n[33189 rows x 1 columns]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = new_df.drop(['unix', 'date', 'symbol', 'open', 'high', 'low', 'Volume BTC', 'Volume USDT', 'tradecount'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "wPmZIXe1l-vn",
    "outputId": "ac29127a-cd54-46f5-8877-ae2cda48bef2"
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4308.83</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4315.32</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4324.35</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4349.99</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4360.69</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33184</th>\n      <td>47084.17</td>\n    </tr>\n    <tr>\n      <th>33185</th>\n      <td>47231.03</td>\n    </tr>\n    <tr>\n      <th>33186</th>\n      <td>46839.01</td>\n    </tr>\n    <tr>\n      <th>33187</th>\n      <td>46420.42</td>\n    </tr>\n    <tr>\n      <th>33188</th>\n      <td>46207.49</td>\n    </tr>\n  </tbody>\n</table>\n<p>33189 rows × 1 columns</p>\n</div>",
      "text/plain": "          close\n0       4308.83\n1       4315.32\n2       4324.35\n3       4349.99\n4       4360.69\n...         ...\n33184  47084.17\n33185  47231.03\n33186  46839.01\n33187  46420.42\n33188  46207.49\n\n[33189 rows x 1 columns]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = df[::-1].reset_index()\n",
    "df = sorted_df.drop(['index'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Rj7WZ4DflPde"
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\t\"\"\"\n",
    "\tFrame a time series as a supervised learning dataset.\n",
    "\tArguments:\n",
    "\t\tdata: Sequence of observations as a list or NumPy array.\n",
    "\t\tn_in: Number of lag observations as input (X).\n",
    "\t\tn_out: Number of observations as output (y).\n",
    "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
    "\tReturns:\n",
    "\t\tPandas DataFrame of series framed for supervised learning.\n",
    "\t\"\"\"\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "s6ovcfLSmzbQ",
    "outputId": "472d9f7e-1b78-4ce2-e1e4-62eb7a879508"
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>var1(t-1)</th>\n      <th>var1(t)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>4308.83</td>\n      <td>4315.32</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4315.32</td>\n      <td>4324.35</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4324.35</td>\n      <td>4349.99</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4349.99</td>\n      <td>4360.69</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4360.69</td>\n      <td>4444.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33184</th>\n      <td>47060.18</td>\n      <td>47084.17</td>\n    </tr>\n    <tr>\n      <th>33185</th>\n      <td>47084.17</td>\n      <td>47231.03</td>\n    </tr>\n    <tr>\n      <th>33186</th>\n      <td>47231.03</td>\n      <td>46839.01</td>\n    </tr>\n    <tr>\n      <th>33187</th>\n      <td>46839.01</td>\n      <td>46420.42</td>\n    </tr>\n    <tr>\n      <th>33188</th>\n      <td>46420.42</td>\n      <td>46207.49</td>\n    </tr>\n  </tbody>\n</table>\n<p>33188 rows × 2 columns</p>\n</div>",
      "text/plain": "       var1(t-1)   var1(t)\n1        4308.83   4315.32\n2        4315.32   4324.35\n3        4324.35   4349.99\n4        4349.99   4360.69\n5        4360.69   4444.00\n...          ...       ...\n33184   47060.18  47084.17\n33185   47084.17  47231.03\n33186   47231.03  46839.01\n33187   46839.01  46420.42\n33188   46420.42  46207.49\n\n[33188 rows x 2 columns]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = series_to_supervised(df)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kwhajhcBnAw0"
   },
   "outputs": [],
   "source": [
    "y = data[\"var1(t)\"].values\n",
    "x = data.drop(\"var1(t)\",axis=1).values\n",
    "y_evolution = data[\"var1(t)\"].values\n",
    "x_evolution = data.drop(\"var1(t)\",axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ov5qBVmunFbQ",
    "outputId": "32644843-a951-4e90-c165-50fbb1a5b4e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 4315.32,  4324.35,  4349.99, ..., 46839.01, 46420.42, 46207.49])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAeEY1PunHGW",
    "outputId": "d6aea5de-3675-4123-bd15-250e8d3f762c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 4308.83],\n       [ 4315.32],\n       [ 4324.35],\n       ...,\n       [47231.03],\n       [46839.01],\n       [46420.42]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgsONOwSnHvl",
    "outputId": "8be7c599-ace2-452b-d956-af8fbced812a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "26550"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=10)\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "538UEYAmnPdw",
    "outputId": "18f812e5-d14e-4c15-c55c-de7e02d5f996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "6638"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UwAe_CavnSh9",
    "outputId": "0d30d4b8-6e0d-4441-d4cc-95f5692f484d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(26550, 1)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VxJmsJ-NnVUX"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MImpznSMnsHx",
    "outputId": "21213362-ed63-4bec-e731-bd32bb06922c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 84363024.0000 - val_loss: 27840378.0000\n",
      "Epoch 2/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 7629419.5000 - val_loss: 2209424.5000\n",
      "Epoch 3/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 430566.6250 - val_loss: 102267.3047\n",
      "Epoch 4/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 45572.1719 - val_loss: 22932.5996\n",
      "Epoch 5/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18802.6484 - val_loss: 17918.8965\n",
      "Epoch 6/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 16756.0312 - val_loss: 16755.9805\n",
      "Epoch 7/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 16195.8223 - val_loss: 18155.5586\n",
      "Epoch 8/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 16099.9541 - val_loss: 15854.2949\n",
      "Epoch 9/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 15775.3457 - val_loss: 18796.5645\n",
      "Epoch 10/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 15401.5166 - val_loss: 16014.7080\n",
      "Epoch 11/300\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 15088.8643 - val_loss: 15559.0938\n",
      "Epoch 12/300\n",
      "27/27 [==============================] - 2s 64ms/step - loss: 14934.7070 - val_loss: 15236.2793\n",
      "Epoch 13/300\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 14766.1660 - val_loss: 15333.1318\n",
      "Epoch 14/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 14686.9131 - val_loss: 15208.1680\n",
      "Epoch 15/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 14818.2178 - val_loss: 15097.4219\n",
      "Epoch 16/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 14721.3750 - val_loss: 15106.9961\n",
      "Epoch 17/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 14738.9727 - val_loss: 15187.1650\n",
      "Epoch 18/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 14702.5127 - val_loss: 16699.8633\n",
      "Epoch 19/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 14937.7969 - val_loss: 15648.8652\n",
      "Epoch 20/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 15093.1201 - val_loss: 15951.6035\n",
      "Epoch 21/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 14923.7334 - val_loss: 15780.1855\n",
      "Epoch 22/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 15436.2803 - val_loss: 16419.4297\n",
      "Epoch 23/300\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 15000.1514 - val_loss: 15044.3359\n",
      "Epoch 24/300\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 14724.9365 - val_loss: 15036.6299\n",
      "Epoch 25/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 15011.1943 - val_loss: 15124.4268\n",
      "Epoch 26/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 14797.1396 - val_loss: 15717.1465\n",
      "Epoch 27/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 15103.1572 - val_loss: 17531.4414\n",
      "Epoch 28/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 15900.8818 - val_loss: 15601.8965\n",
      "Epoch 29/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 14894.1055 - val_loss: 15865.2002\n",
      "Epoch 30/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 14876.1914 - val_loss: 16254.7832\n",
      "Epoch 31/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 15178.6904 - val_loss: 15040.3457\n",
      "Epoch 32/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 14855.9531 - val_loss: 15226.7275\n",
      "Epoch 33/300\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 15256.6396 - val_loss: 15060.7119\n",
      "Epoch 34/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 15453.5283 - val_loss: 15334.0908\n",
      "Epoch 35/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 17441.8301 - val_loss: 15175.5195\n",
      "Epoch 36/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 15221.2695 - val_loss: 15600.5254\n",
      "Epoch 37/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 14754.9141 - val_loss: 15279.2783\n",
      "Epoch 38/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 15044.2461 - val_loss: 16990.4531\n",
      "Epoch 39/300\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 16384.7637 - val_loss: 15957.0605\n",
      "Epoch 40/300\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 15096.9717 - val_loss: 15240.1504\n",
      "Epoch 41/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 15118.3271 - val_loss: 15694.4541\n",
      "Epoch 42/300\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 14845.9414 - val_loss: 15333.1260\n",
      "Epoch 43/300\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 15769.5977 - val_loss: 19074.3984\n",
      "Epoch 44/300\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 17778.7480 - val_loss: 19816.0996\n",
      "Epoch 45/300\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 16420.2520 - val_loss: 15933.6934\n",
      "Epoch 46/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 15241.5264 - val_loss: 15135.9805\n",
      "Epoch 47/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 14933.9062 - val_loss: 15791.4072\n",
      "Epoch 48/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 17332.8164 - val_loss: 18266.6797\n",
      "Epoch 49/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 17010.9473 - val_loss: 15034.8330\n",
      "Epoch 50/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 15017.6045 - val_loss: 15978.1572\n",
      "Epoch 51/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 15464.9639 - val_loss: 16058.6992\n",
      "Epoch 52/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 15434.6025 - val_loss: 16076.3984\n",
      "Epoch 53/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 18285.4297 - val_loss: 15538.6836\n",
      "Epoch 54/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 15715.8398 - val_loss: 15375.8965\n",
      "Epoch 55/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 15366.8994 - val_loss: 15185.1514\n",
      "Epoch 56/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 15928.9512 - val_loss: 23709.7637\n",
      "Epoch 57/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 15802.1387 - val_loss: 15805.4346\n",
      "Epoch 58/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 15504.8701 - val_loss: 15243.7695\n",
      "Epoch 59/300\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 15625.5361 - val_loss: 17216.9590\n",
      "Epoch 60/300\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 14890.1797 - val_loss: 16096.2568\n",
      "Epoch 61/300\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 14985.3027 - val_loss: 16001.7744\n",
      "Epoch 62/300\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 16149.1855 - val_loss: 20367.8848\n",
      "Epoch 63/300\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 18593.5684 - val_loss: 24081.8359\n",
      "Epoch 64/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 17431.0977 - val_loss: 15199.5693\n",
      "Epoch 65/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 16873.6523 - val_loss: 17898.8281\n",
      "Epoch 66/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 18156.8613 - val_loss: 16351.2314\n",
      "Epoch 67/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 16822.7559 - val_loss: 16739.4609\n",
      "Epoch 68/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 17259.5586 - val_loss: 15134.2275\n",
      "Epoch 69/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 16365.9453 - val_loss: 19659.8320\n",
      "Epoch 70/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 24924.5938 - val_loss: 20505.4180\n",
      "Epoch 71/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 16487.5488 - val_loss: 18867.0332\n",
      "Epoch 72/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 25721.3066 - val_loss: 17601.4316\n",
      "Epoch 73/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 17568.7188 - val_loss: 20473.5117\n",
      "Epoch 74/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 15700.0039 - val_loss: 15410.3252\n",
      "Epoch 75/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 17973.2871 - val_loss: 37542.0820\n",
      "Epoch 76/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 19772.5430 - val_loss: 15689.1670\n",
      "Epoch 77/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 18693.5000 - val_loss: 17914.3711\n",
      "Epoch 78/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 20455.5820 - val_loss: 15163.8447\n",
      "Epoch 79/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 19850.4922 - val_loss: 27979.5078\n",
      "Epoch 80/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 20450.0078 - val_loss: 17576.3633\n",
      "Epoch 81/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 17623.1406 - val_loss: 15808.4131\n",
      "Epoch 82/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 18895.2012 - val_loss: 16237.8037\n",
      "Epoch 83/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 18212.7832 - val_loss: 26403.1113\n",
      "Epoch 84/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 19513.1484 - val_loss: 34691.9688\n",
      "Epoch 85/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 29477.1484 - val_loss: 20098.8496\n",
      "Epoch 86/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 23125.1445 - val_loss: 17098.3613\n",
      "Epoch 87/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 29929.9238 - val_loss: 15181.5225\n",
      "Epoch 88/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 30265.2871 - val_loss: 15101.9561\n",
      "Epoch 89/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 24086.4102 - val_loss: 24838.5625\n",
      "Epoch 90/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 30190.2637 - val_loss: 66745.0312\n",
      "Epoch 91/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 32573.8711 - val_loss: 15014.0186\n",
      "Epoch 92/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 26927.2363 - val_loss: 16575.0586\n",
      "Epoch 93/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 22600.7246 - val_loss: 15178.4229\n",
      "Epoch 94/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 19740.6719 - val_loss: 15121.2598\n",
      "Epoch 95/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 21772.4141 - val_loss: 28725.5840\n",
      "Epoch 96/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 21705.4922 - val_loss: 26987.6719\n",
      "Epoch 97/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 49571.0352 - val_loss: 40583.2812\n",
      "Epoch 98/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 37876.9180 - val_loss: 20948.2598\n",
      "Epoch 99/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 26690.6172 - val_loss: 25292.2637\n",
      "Epoch 100/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 21397.3770 - val_loss: 29726.1641\n",
      "Epoch 101/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 17925.3340 - val_loss: 37322.6289\n",
      "Epoch 102/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 45177.2344 - val_loss: 133080.8125\n",
      "Epoch 103/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 70003.2891 - val_loss: 48902.0820\n",
      "Epoch 104/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 56160.8555 - val_loss: 54049.2969\n",
      "Epoch 105/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 70308.2344 - val_loss: 88407.3125\n",
      "Epoch 106/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 39732.0664 - val_loss: 15224.7969\n",
      "Epoch 107/300\n",
      "27/27 [==============================] - 1s 56ms/step - loss: 23758.4941 - val_loss: 90130.4141\n",
      "Epoch 108/300\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 43081.2266 - val_loss: 38329.3086\n",
      "Epoch 109/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 21848.2617 - val_loss: 17778.4902\n",
      "Epoch 110/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 21182.9316 - val_loss: 15892.2930\n",
      "Epoch 111/300\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 28167.4531 - val_loss: 40346.1602\n",
      "Epoch 112/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 18800.3477 - val_loss: 15310.6973\n",
      "Epoch 113/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 20370.8281 - val_loss: 38595.9961\n",
      "Epoch 114/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 26983.8945 - val_loss: 17982.2441\n",
      "Epoch 115/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 63111.6133 - val_loss: 23207.3965\n",
      "Epoch 116/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 77757.3906 - val_loss: 17510.3652\n",
      "Epoch 117/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 44815.7852 - val_loss: 124325.6094\n",
      "Epoch 118/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 38357.5039 - val_loss: 56448.5781\n",
      "Epoch 119/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 46103.2812 - val_loss: 105298.9922\n",
      "Epoch 120/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 41351.4766 - val_loss: 37708.6602\n",
      "Epoch 121/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 21557.2227 - val_loss: 15957.7773\n",
      "Epoch 122/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 20007.4902 - val_loss: 16368.8506\n",
      "Epoch 123/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 67096.3984 - val_loss: 15302.3662\n",
      "Epoch 124/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 33507.6953 - val_loss: 44882.9492\n",
      "Epoch 125/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 46991.6875 - val_loss: 17982.4961\n",
      "Epoch 126/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 34929.3594 - val_loss: 31967.6738\n",
      "Epoch 127/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 27154.7500 - val_loss: 17819.6055\n",
      "Epoch 128/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 36571.8984 - val_loss: 86716.9141\n",
      "Epoch 129/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 116698.4922 - val_loss: 23701.6426\n",
      "Epoch 130/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 39270.0586 - val_loss: 149260.7812\n",
      "Epoch 131/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 47666.5430 - val_loss: 28950.8945\n",
      "Epoch 132/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 17241.2578 - val_loss: 15063.9541\n",
      "Epoch 133/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 32564.8867 - val_loss: 16267.7539\n",
      "Epoch 134/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 25062.6562 - val_loss: 22236.4062\n",
      "Epoch 135/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 34816.8828 - val_loss: 20067.8418\n",
      "Epoch 136/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 34363.2617 - val_loss: 28146.0117\n",
      "Epoch 137/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 35046.9922 - val_loss: 21082.4062\n",
      "Epoch 138/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 32934.0195 - val_loss: 33786.5508\n",
      "Epoch 139/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 22731.7656 - val_loss: 42260.8945\n",
      "Epoch 140/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 30916.1211 - val_loss: 83614.3984\n",
      "Epoch 141/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 39347.5625 - val_loss: 26004.1055\n",
      "Epoch 142/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 18597.5137 - val_loss: 16527.1582\n",
      "Epoch 143/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 266678.7500 - val_loss: 775548.7500\n",
      "Epoch 144/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 184004.9844 - val_loss: 119575.9297\n",
      "Epoch 145/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 75883.4453 - val_loss: 23779.0176\n",
      "Epoch 146/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 28447.6465 - val_loss: 20559.2559\n",
      "Epoch 147/300\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 16047.5332 - val_loss: 15191.3857\n",
      "Epoch 148/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 20725.2012 - val_loss: 59795.5859\n",
      "Epoch 149/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 32124.5098 - val_loss: 89230.3438\n",
      "Epoch 150/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 32241.5762 - val_loss: 16645.4062\n",
      "Epoch 151/300\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 18172.6328 - val_loss: 34417.6719\n",
      "Epoch 152/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 23281.1973 - val_loss: 15494.9082\n",
      "Epoch 153/300\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 22212.1973 - val_loss: 31045.5938\n",
      "Epoch 154/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 23992.9512 - val_loss: 17267.6680\n",
      "Epoch 155/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 21426.6895 - val_loss: 16310.0342\n",
      "Epoch 156/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 18931.1094 - val_loss: 35612.2148\n",
      "Epoch 157/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 24099.3574 - val_loss: 15772.5605\n",
      "Epoch 158/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 20250.1504 - val_loss: 16529.7578\n",
      "Epoch 159/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 17197.1797 - val_loss: 15040.4570\n",
      "Epoch 160/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 21878.5918 - val_loss: 18434.1211\n",
      "Epoch 161/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 24412.3574 - val_loss: 25353.8125\n",
      "Epoch 162/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 32153.6309 - val_loss: 24840.4121\n",
      "Epoch 163/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 131350.3594 - val_loss: 75090.7500\n",
      "Epoch 164/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 27248.6152 - val_loss: 15646.9482\n",
      "Epoch 165/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 28714.0371 - val_loss: 28554.0625\n",
      "Epoch 166/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 31638.3594 - val_loss: 20548.0156\n",
      "Epoch 167/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 21576.6523 - val_loss: 55176.4414\n",
      "Epoch 168/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 23153.1445 - val_loss: 15014.3115\n",
      "Epoch 169/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 75003.3516 - val_loss: 16321.7861\n",
      "Epoch 170/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 138093.4375 - val_loss: 59341.1094\n",
      "Epoch 171/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 22929.0000 - val_loss: 20621.8750\n",
      "Epoch 172/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 49146.5430 - val_loss: 15225.2451\n",
      "Epoch 173/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 17654.2852 - val_loss: 18992.7383\n",
      "Epoch 174/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 43389.3320 - val_loss: 93483.9453\n",
      "Epoch 175/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 41452.5625 - val_loss: 16544.0273\n",
      "Epoch 176/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 59785.9805 - val_loss: 76161.3750\n",
      "Epoch 177/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 31948.7402 - val_loss: 23596.9277\n",
      "Epoch 178/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 18140.6816 - val_loss: 17218.9023\n",
      "Epoch 179/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18819.9141 - val_loss: 15366.1562\n",
      "Epoch 180/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 44264.6602 - val_loss: 33491.9531\n",
      "Epoch 181/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 22202.3359 - val_loss: 26003.1309\n",
      "Epoch 182/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 16113.9932 - val_loss: 15189.8125\n",
      "Epoch 183/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 21709.2539 - val_loss: 58321.5820\n",
      "Epoch 184/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 43451.9219 - val_loss: 22167.6895\n",
      "Epoch 185/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 42308.2539 - val_loss: 46976.1602\n",
      "Epoch 186/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 29123.8301 - val_loss: 110169.9766\n",
      "Epoch 187/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 25835.5293 - val_loss: 48542.5547\n",
      "Epoch 188/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 44107.2188 - val_loss: 15996.9248\n",
      "Epoch 189/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 18324.0801 - val_loss: 28745.9805\n",
      "Epoch 190/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 39289.0352 - val_loss: 18549.9102\n",
      "Epoch 191/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 109230.3047 - val_loss: 20817.1230\n",
      "Epoch 192/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 76231.3594 - val_loss: 19587.0195\n",
      "Epoch 193/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 21601.4297 - val_loss: 20207.4316\n",
      "Epoch 194/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 17179.5176 - val_loss: 17558.1504\n",
      "Epoch 195/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 31752.3770 - val_loss: 75966.3594\n",
      "Epoch 196/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 45240.8789 - val_loss: 15476.4629\n",
      "Epoch 197/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 25263.7871 - val_loss: 21384.3906\n",
      "Epoch 198/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 22743.7461 - val_loss: 51012.2617\n",
      "Epoch 199/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 49260.3008 - val_loss: 68362.1562\n",
      "Epoch 200/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 38608.3320 - val_loss: 15497.6924\n",
      "Epoch 201/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 32992.9688 - val_loss: 15545.7256\n",
      "Epoch 202/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 27589.6934 - val_loss: 19753.3145\n",
      "Epoch 203/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 42442.4844 - val_loss: 96694.7891\n",
      "Epoch 204/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 49707.1445 - val_loss: 65968.5469\n",
      "Epoch 205/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 32302.3262 - val_loss: 15272.0752\n",
      "Epoch 206/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 58151.6211 - val_loss: 16825.4980\n",
      "Epoch 207/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 22202.4492 - val_loss: 15160.7051\n",
      "Epoch 208/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 21545.2344 - val_loss: 24075.9395\n",
      "Epoch 209/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 23830.7363 - val_loss: 16495.6406\n",
      "Epoch 210/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 31623.3262 - val_loss: 44358.3984\n",
      "Epoch 211/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 44454.4336 - val_loss: 25733.5840\n",
      "Epoch 212/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 61325.4258 - val_loss: 48337.6406\n",
      "Epoch 213/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 22248.6992 - val_loss: 27211.6270\n",
      "Epoch 214/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 17955.9023 - val_loss: 16682.8848\n",
      "Epoch 215/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 26958.3086 - val_loss: 19149.0410\n",
      "Epoch 216/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 78578.3047 - val_loss: 75367.2578\n",
      "Epoch 217/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 40949.9258 - val_loss: 32055.2461\n",
      "Epoch 218/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 22495.3145 - val_loss: 46050.4492\n",
      "Epoch 219/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 39685.2266 - val_loss: 112471.0469\n",
      "Epoch 220/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 36872.0938 - val_loss: 23765.5156\n",
      "Epoch 221/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 21637.8398 - val_loss: 16888.3887\n",
      "Epoch 222/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 21210.5078 - val_loss: 41301.6484\n",
      "Epoch 223/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 96317.7188 - val_loss: 319083.9688\n",
      "Epoch 224/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 86099.6016 - val_loss: 89056.2734\n",
      "Epoch 225/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 32908.8711 - val_loss: 37246.4727\n",
      "Epoch 226/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 52095.2539 - val_loss: 44478.0430\n",
      "Epoch 227/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 51579.5586 - val_loss: 122045.7188\n",
      "Epoch 228/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 45807.5234 - val_loss: 31051.0645\n",
      "Epoch 229/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 22628.0215 - val_loss: 24833.5938\n",
      "Epoch 230/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 22181.7598 - val_loss: 65682.0312\n",
      "Epoch 231/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 64867.6133 - val_loss: 27645.5586\n",
      "Epoch 232/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 54787.5898 - val_loss: 80047.4766\n",
      "Epoch 233/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 53554.7422 - val_loss: 23812.0566\n",
      "Epoch 234/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 21276.9609 - val_loss: 37129.4023\n",
      "Epoch 235/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 25872.0996 - val_loss: 62067.6211\n",
      "Epoch 236/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 34799.5898 - val_loss: 18230.1406\n",
      "Epoch 237/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 22462.5312 - val_loss: 29970.9551\n",
      "Epoch 238/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 52805.5195 - val_loss: 46862.2930\n",
      "Epoch 239/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 150840.3750 - val_loss: 43681.9492\n",
      "Epoch 240/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 18688.5000 - val_loss: 26689.1035\n",
      "Epoch 241/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 20281.6719 - val_loss: 20848.2500\n",
      "Epoch 242/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 22864.9238 - val_loss: 17665.5840\n",
      "Epoch 243/300\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 27406.6875 - val_loss: 19489.5742\n",
      "Epoch 244/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 34106.2148 - val_loss: 43832.3789\n",
      "Epoch 245/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 22749.3984 - val_loss: 15891.5723\n",
      "Epoch 246/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 20020.5156 - val_loss: 49847.9102\n",
      "Epoch 247/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 29566.1816 - val_loss: 15398.6670\n",
      "Epoch 248/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 22169.5957 - val_loss: 16590.7148\n",
      "Epoch 249/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 45259.4492 - val_loss: 32077.7773\n",
      "Epoch 250/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 44547.9062 - val_loss: 54453.5859\n",
      "Epoch 251/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 28283.4727 - val_loss: 16061.9443\n",
      "Epoch 252/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 21943.2109 - val_loss: 15352.5039\n",
      "Epoch 253/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 32546.0762 - val_loss: 25291.6250\n",
      "Epoch 254/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 43685.1797 - val_loss: 96282.8516\n",
      "Epoch 255/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 59593.5977 - val_loss: 109924.3359\n",
      "Epoch 256/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 73401.5312 - val_loss: 24618.0781\n",
      "Epoch 257/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 30931.2285 - val_loss: 17215.0645\n",
      "Epoch 258/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18901.2773 - val_loss: 18494.9375\n",
      "Epoch 259/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 25076.3457 - val_loss: 33629.6875\n",
      "Epoch 260/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 29844.2480 - val_loss: 39071.2539\n",
      "Epoch 261/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 37853.4141 - val_loss: 23058.2637\n",
      "Epoch 262/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 34162.0039 - val_loss: 75595.1172\n",
      "Epoch 263/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 35610.8047 - val_loss: 40111.5039\n",
      "Epoch 264/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 24581.0566 - val_loss: 61293.1445\n",
      "Epoch 265/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 25328.3477 - val_loss: 39361.4883\n",
      "Epoch 266/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 37178.4648 - val_loss: 34674.5820\n",
      "Epoch 267/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 36179.7656 - val_loss: 43074.3828\n",
      "Epoch 268/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 53673.8516 - val_loss: 94901.4297\n",
      "Epoch 269/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 41231.6211 - val_loss: 24356.8066\n",
      "Epoch 270/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 37869.5977 - val_loss: 82721.0859\n",
      "Epoch 271/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 73322.0078 - val_loss: 44130.5820\n",
      "Epoch 272/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 136245.9219 - val_loss: 213913.4375\n",
      "Epoch 273/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 67222.2891 - val_loss: 15512.5762\n",
      "Epoch 274/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 16837.9531 - val_loss: 23173.4668\n",
      "Epoch 275/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 27735.8984 - val_loss: 20935.0449\n",
      "Epoch 276/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 28253.9590 - val_loss: 19864.6211\n",
      "Epoch 277/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 44054.3828 - val_loss: 25181.6836\n",
      "Epoch 278/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 26154.2012 - val_loss: 21875.8906\n",
      "Epoch 279/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 22837.7363 - val_loss: 17090.0195\n",
      "Epoch 280/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 19162.6758 - val_loss: 20925.5781\n",
      "Epoch 281/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 31766.5176 - val_loss: 32340.6016\n",
      "Epoch 282/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 20297.2422 - val_loss: 22523.4395\n",
      "Epoch 283/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 31915.5781 - val_loss: 23664.2559\n",
      "Epoch 284/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18607.8770 - val_loss: 31340.9590\n",
      "Epoch 285/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 26838.7949 - val_loss: 56193.9688\n",
      "Epoch 286/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 78763.1562 - val_loss: 58231.2891\n",
      "Epoch 287/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18888.4160 - val_loss: 15746.2666\n",
      "Epoch 288/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 20940.0859 - val_loss: 17894.3066\n",
      "Epoch 289/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 22962.5898 - val_loss: 20019.9941\n",
      "Epoch 290/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 32487.7598 - val_loss: 55363.9727\n",
      "Epoch 291/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 44564.7109 - val_loss: 15196.8506\n",
      "Epoch 292/300\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 43803.4453 - val_loss: 15028.2373\n",
      "Epoch 293/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 32752.7539 - val_loss: 24905.9980\n",
      "Epoch 294/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 40404.7461 - val_loss: 17376.2578\n",
      "Epoch 295/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 38181.2031 - val_loss: 138528.2188\n",
      "Epoch 296/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 80330.6953 - val_loss: 33201.1523\n",
      "Epoch 297/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 46877.5469 - val_loss: 15242.7988\n",
      "Epoch 298/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 30172.6230 - val_loss: 38130.1797\n",
      "Epoch 299/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 33867.1953 - val_loss: 59775.2969\n",
      "Epoch 300/300\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 34715.9648 - val_loss: 17443.8066\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=x_train, y = y_train,validation_data=(x_test,y_test),epochs=300, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uz7bsYSGvaMP"
   },
   "outputs": [],
   "source": [
    "loss_value = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "xur6xAVnvfSm",
    "outputId": "55406ad5-98e5-4304-a652-bd8ab7d29de5"
   },
   "outputs": [],
   "source": [
    "loss_value.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIrrvcE5vn6B",
    "outputId": "6b2ff81b-bf8b-4170-f817-fac2b58b8f89"
   },
   "outputs": [],
   "source": [
    "predict_que = model.predict(x_test)\n",
    "predict_que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Er76Kv2Evo04",
    "outputId": "ac9fd08c-2c21-4bb8-f41a-42b2c06242c5"
   },
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test,predict_que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "4LqqFm-mvuSX",
    "outputId": "1a957f81-9c59-4320-9cda-2e7e9365267c"
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_test,predict_que)\n",
    "plt.plot(y_test,y_test,\"g-*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAhjpWu9vv4e",
    "outputId": "14cb9edd-7bbf-469c-ff8e-150067fefa7a"
   },
   "outputs": [],
   "source": [
    "data.iloc[32900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KxjJ_-SGvzvr",
    "outputId": "55c75bb3-c77f-4589-f53d-74d5c53eb400"
   },
   "outputs": [],
   "source": [
    "new_prices = data.drop(\"var1(t)\",axis=1).iloc[32900]\n",
    "new_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RI5Y8apRv2A5",
    "outputId": "f1fca4b4-2153-49b4-86d2-34d7ac869f89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x205d790afa0>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "array([[ 9266.758 ],\n       [ 6584.8525],\n       [ 6340.2637],\n       ...,\n       [ 8137.492 ],\n       [26932.93  ],\n       [ 6335.23  ]], dtype=float32)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "68.1872089834923"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x205db14c0a0>]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "var1(t-1)    34150.23\nvar1(t)      33906.57\nName: 32901, dtype: float64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "var1(t-1)    34150.23\nName: 32901, dtype: float64"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "array([[0.68983373]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prices = scaler.transform(new_prices.values.reshape(-1,1))\n",
    "new_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9y9PWHhv20e",
    "outputId": "f0791ffe-826d-439a-942e-e528a9184972"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[33982.984]], dtype=float32)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_yUwjf4v_-X",
    "outputId": "acaef4e9-9798-4894-c5f4-e489b30809cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[38681.54]], dtype=float32)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_price = [[38875]]\n",
    "current_price = scaler.transform(current_price)\n",
    "model.predict(current_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kF66QBaewGzX",
    "outputId": "9486f2dc-d581-4f24-af51-2f924c99412d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 4476.2812],\n       [ 4482.6963],\n       [ 4491.621 ],\n       ...,\n       [46994.715 ],\n       [46606.43  ],\n       [46191.83  ]], dtype=float32)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_predict_que =scaler.fit_transform(x)\n",
    "predicted_que = model.predict(scaled_predict_que)\n",
    "predicted_que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-zkXAStwIed",
    "outputId": "be31e6a6-8f07-4a34-902c-4cc1de696f5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dogru bilinen sayisi ->3433\n",
      "Yanlis bilinen sayisi ->3204\n",
      "Accuracy->0.5172517703781829\n"
     ]
    }
   ],
   "source": [
    "values_correct = 0\n",
    "values_incorrect = 0\n",
    "for a in range(6637):\n",
    "  if y_evolution[a] > x_evolution[a] and predicted_que[a] > x_evolution[a]:\n",
    "    values_correct += 1\n",
    "  elif y_evolution[a] < x_evolution[a] and predicted_que[a] < x_evolution[a]:\n",
    "    values_correct += 1\n",
    "  else:\n",
    "    values_incorrect += 1\n",
    "print(\"Dogru bilinen sayisi ->{}\".format(values_correct))\n",
    "print(\"Yanlis bilinen sayisi ->{}\".format(values_incorrect))\n",
    "print(\"Accuracy->{}\".format(float(values_correct)/6637))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6arNXOHH4MvA",
    "outputId": "f4079785-1fea-48ad-93cc-da880701c085"
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "import weakref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_thread.RLock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f573f57429d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpkl_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"pickle_model.pkl\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkl_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle '_thread.RLock' object"
     ]
    }
   ],
   "source": [
    "pkl_filename = \"pickle_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "time series - single variate 1H",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('CENGAKAYRA': conda)",
   "name": "python385jvsc74a57bd0347af57ec59b63f62ae9eaaa9cdbc18f499ef3a6f42f545d9e7235b70ab555d3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}