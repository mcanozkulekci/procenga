{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "UDXvd4uwhZjc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "TTD1DUEUlFrC",
    "outputId": "ddca7869-40e4-4e61-cd59-1aa63c600cad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unix</th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Volume BTC</th>\n",
       "      <th>Volume USDT</th>\n",
       "      <th>tradecount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.612915e+12</td>\n",
       "      <td>2021-02-10 00:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>46420.42</td>\n",
       "      <td>46557.24</td>\n",
       "      <td>46052.52</td>\n",
       "      <td>46207.49</td>\n",
       "      <td>639.739914</td>\n",
       "      <td>2.960948e+07</td>\n",
       "      <td>20978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.612912e+12</td>\n",
       "      <td>2021-02-09 23:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>46839.99</td>\n",
       "      <td>46860.00</td>\n",
       "      <td>46201.37</td>\n",
       "      <td>46420.42</td>\n",
       "      <td>2790.416785</td>\n",
       "      <td>1.296341e+08</td>\n",
       "      <td>113106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.612908e+12</td>\n",
       "      <td>2021-02-09 22:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>47241.92</td>\n",
       "      <td>47241.92</td>\n",
       "      <td>46440.52</td>\n",
       "      <td>46839.01</td>\n",
       "      <td>2914.614311</td>\n",
       "      <td>1.363150e+08</td>\n",
       "      <td>105273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.612904e+12</td>\n",
       "      <td>2021-02-09 21:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>47084.16</td>\n",
       "      <td>47461.06</td>\n",
       "      <td>46995.92</td>\n",
       "      <td>47231.03</td>\n",
       "      <td>2564.524939</td>\n",
       "      <td>1.211090e+08</td>\n",
       "      <td>77433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.612901e+12</td>\n",
       "      <td>2021-02-09 20:00:00</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>47060.38</td>\n",
       "      <td>47499.43</td>\n",
       "      <td>46668.48</td>\n",
       "      <td>47084.17</td>\n",
       "      <td>3254.702714</td>\n",
       "      <td>1.532251e+08</td>\n",
       "      <td>100788.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33184</th>\n",
       "      <td>1.502957e+09</td>\n",
       "      <td>2017-08-17 08-AM</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>4349.99</td>\n",
       "      <td>4377.85</td>\n",
       "      <td>4333.32</td>\n",
       "      <td>4360.69</td>\n",
       "      <td>0.949900</td>\n",
       "      <td>4.139700e+03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33185</th>\n",
       "      <td>1.502953e+09</td>\n",
       "      <td>2017-08-17 07-AM</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>4324.35</td>\n",
       "      <td>4349.99</td>\n",
       "      <td>4287.41</td>\n",
       "      <td>4349.99</td>\n",
       "      <td>4.440000</td>\n",
       "      <td>1.924106e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33186</th>\n",
       "      <td>1.502950e+09</td>\n",
       "      <td>2017-08-17 06-AM</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>4315.32</td>\n",
       "      <td>4345.45</td>\n",
       "      <td>4309.37</td>\n",
       "      <td>4324.35</td>\n",
       "      <td>7.230000</td>\n",
       "      <td>3.128231e+04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33187</th>\n",
       "      <td>1.502946e+09</td>\n",
       "      <td>2017-08-17 05-AM</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>4308.83</td>\n",
       "      <td>4328.69</td>\n",
       "      <td>4291.37</td>\n",
       "      <td>4315.32</td>\n",
       "      <td>23.230000</td>\n",
       "      <td>1.003048e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33188</th>\n",
       "      <td>1.502942e+09</td>\n",
       "      <td>2017-08-17 04-AM</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>16199.91</td>\n",
       "      <td>16199.91</td>\n",
       "      <td>4261.32</td>\n",
       "      <td>4308.83</td>\n",
       "      <td>44.510000</td>\n",
       "      <td>1.909529e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33189 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               unix                 date    symbol      open      high  \\\n",
       "0      1.612915e+12  2021-02-10 00:00:00  BTC/USDT  46420.42  46557.24   \n",
       "1      1.612912e+12  2021-02-09 23:00:00  BTC/USDT  46839.99  46860.00   \n",
       "2      1.612908e+12  2021-02-09 22:00:00  BTC/USDT  47241.92  47241.92   \n",
       "3      1.612904e+12  2021-02-09 21:00:00  BTC/USDT  47084.16  47461.06   \n",
       "4      1.612901e+12  2021-02-09 20:00:00  BTC/USDT  47060.38  47499.43   \n",
       "...             ...                  ...       ...       ...       ...   \n",
       "33184  1.502957e+09     2017-08-17 08-AM  BTC/USDT   4349.99   4377.85   \n",
       "33185  1.502953e+09     2017-08-17 07-AM  BTC/USDT   4324.35   4349.99   \n",
       "33186  1.502950e+09     2017-08-17 06-AM  BTC/USDT   4315.32   4345.45   \n",
       "33187  1.502946e+09     2017-08-17 05-AM  BTC/USDT   4308.83   4328.69   \n",
       "33188  1.502942e+09     2017-08-17 04-AM  BTC/USDT  16199.91  16199.91   \n",
       "\n",
       "            low     close   Volume BTC   Volume USDT  tradecount  \n",
       "0      46052.52  46207.49   639.739914  2.960948e+07     20978.0  \n",
       "1      46201.37  46420.42  2790.416785  1.296341e+08    113106.0  \n",
       "2      46440.52  46839.01  2914.614311  1.363150e+08    105273.0  \n",
       "3      46995.92  47231.03  2564.524939  1.211090e+08     77433.0  \n",
       "4      46668.48  47084.17  3254.702714  1.532251e+08    100788.0  \n",
       "...         ...       ...          ...           ...         ...  \n",
       "33184   4333.32   4360.69     0.949900  4.139700e+03         NaN  \n",
       "33185   4287.41   4349.99     4.440000  1.924106e+04         NaN  \n",
       "33186   4309.37   4324.35     7.230000  3.128231e+04         NaN  \n",
       "33187   4291.37   4315.32    23.230000  1.003048e+05         NaN  \n",
       "33188   4261.32   4308.83    44.510000  1.909529e+05         NaN  \n",
       "\n",
       "[33189 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_csv(\"Binance_BTCUSDT_1h.csv\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "R9KhXRQMlajh",
    "outputId": "5fe4b964-e266-4b69-fff7-1b91249bdf75"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46207.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46420.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46839.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47231.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47084.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33184</th>\n",
       "      <td>4360.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33185</th>\n",
       "      <td>4349.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33186</th>\n",
       "      <td>4324.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33187</th>\n",
       "      <td>4315.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33188</th>\n",
       "      <td>4308.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33189 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          close\n",
       "0      46207.49\n",
       "1      46420.42\n",
       "2      46839.01\n",
       "3      47231.03\n",
       "4      47084.17\n",
       "...         ...\n",
       "33184   4360.69\n",
       "33185   4349.99\n",
       "33186   4324.35\n",
       "33187   4315.32\n",
       "33188   4308.83\n",
       "\n",
       "[33189 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = new_df.drop(['unix', 'date', 'symbol', 'open', 'high', 'low', 'Volume BTC', 'Volume USDT', 'tradecount'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "wPmZIXe1l-vn",
    "outputId": "ac29127a-cd54-46f5-8877-ae2cda48bef2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4308.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4315.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4324.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4349.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4360.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33184</th>\n",
       "      <td>47084.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33185</th>\n",
       "      <td>47231.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33186</th>\n",
       "      <td>46839.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33187</th>\n",
       "      <td>46420.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33188</th>\n",
       "      <td>46207.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33189 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          close\n",
       "0       4308.83\n",
       "1       4315.32\n",
       "2       4324.35\n",
       "3       4349.99\n",
       "4       4360.69\n",
       "...         ...\n",
       "33184  47084.17\n",
       "33185  47231.03\n",
       "33186  46839.01\n",
       "33187  46420.42\n",
       "33188  46207.49\n",
       "\n",
       "[33189 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = df[::-1].reset_index()\n",
    "df = sorted_df.drop(['index'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Rj7WZ4DflPde"
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\t\"\"\"\n",
    "\tFrame a time series as a supervised learning dataset.\n",
    "\tArguments:\n",
    "\t\tdata: Sequence of observations as a list or NumPy array.\n",
    "\t\tn_in: Number of lag observations as input (X).\n",
    "\t\tn_out: Number of observations as output (y).\n",
    "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
    "\tReturns:\n",
    "\t\tPandas DataFrame of series framed for supervised learning.\n",
    "\t\"\"\"\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "s6ovcfLSmzbQ",
    "outputId": "472d9f7e-1b78-4ce2-e1e4-62eb7a879508"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4308.83</td>\n",
       "      <td>4315.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4315.32</td>\n",
       "      <td>4324.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4324.35</td>\n",
       "      <td>4349.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4349.99</td>\n",
       "      <td>4360.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4360.69</td>\n",
       "      <td>4444.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33184</th>\n",
       "      <td>47060.18</td>\n",
       "      <td>47084.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33185</th>\n",
       "      <td>47084.17</td>\n",
       "      <td>47231.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33186</th>\n",
       "      <td>47231.03</td>\n",
       "      <td>46839.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33187</th>\n",
       "      <td>46839.01</td>\n",
       "      <td>46420.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33188</th>\n",
       "      <td>46420.42</td>\n",
       "      <td>46207.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33188 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1(t-1)   var1(t)\n",
       "1        4308.83   4315.32\n",
       "2        4315.32   4324.35\n",
       "3        4324.35   4349.99\n",
       "4        4349.99   4360.69\n",
       "5        4360.69   4444.00\n",
       "...          ...       ...\n",
       "33184   47060.18  47084.17\n",
       "33185   47084.17  47231.03\n",
       "33186   47231.03  46839.01\n",
       "33187   46839.01  46420.42\n",
       "33188   46420.42  46207.49\n",
       "\n",
       "[33188 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = series_to_supervised(df)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kwhajhcBnAw0"
   },
   "outputs": [],
   "source": [
    "y = data[\"var1(t)\"].values\n",
    "x = data.drop(\"var1(t)\",axis=1).values\n",
    "y_evolution = data[\"var1(t)\"].values\n",
    "x_evolution = data.drop(\"var1(t)\",axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ov5qBVmunFbQ",
    "outputId": "32644843-a951-4e90-c165-50fbb1a5b4e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4315.32,  4324.35,  4349.99, ..., 46839.01, 46420.42, 46207.49])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAeEY1PunHGW",
    "outputId": "d6aea5de-3675-4123-bd15-250e8d3f762c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4308.83],\n",
       "       [ 4315.32],\n",
       "       [ 4324.35],\n",
       "       ...,\n",
       "       [47231.03],\n",
       "       [46839.01],\n",
       "       [46420.42]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgsONOwSnHvl",
    "outputId": "8be7c599-ace2-452b-d956-af8fbced812a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26550"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=10)\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "538UEYAmnPdw",
    "outputId": "18f812e5-d14e-4c15-c55c-de7e02d5f996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6638"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UwAe_CavnSh9",
    "outputId": "0d30d4b8-6e0d-4441-d4cc-95f5692f484d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26550, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VxJmsJ-NnVUX"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MImpznSMnsHx",
    "outputId": "21213362-ed63-4bec-e731-bd32bb06922c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 115111116.8571 - val_loss: 23527730.0000\n",
      "Epoch 2/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 12636328.4286 - val_loss: 2195557.7500\n",
      "Epoch 3/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 812872.5670 - val_loss: 148820.2031\n",
      "Epoch 4/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 90808.8542 - val_loss: 31473.7227\n",
      "Epoch 5/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 22932.6496 - val_loss: 18464.4453\n",
      "Epoch 6/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 18630.6704 - val_loss: 17421.7598\n",
      "Epoch 7/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18113.8903 - val_loss: 16529.7773\n",
      "Epoch 8/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 16636.4161 - val_loss: 15871.9688\n",
      "Epoch 9/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 15608.9976 - val_loss: 15635.6143\n",
      "Epoch 10/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 15976.2642 - val_loss: 15547.1826\n",
      "Epoch 11/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 14659.4814 - val_loss: 15571.0752\n",
      "Epoch 12/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 14026.1814 - val_loss: 15244.3291\n",
      "Epoch 13/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 13235.7599 - val_loss: 16379.5283\n",
      "Epoch 14/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 16166.8296 - val_loss: 15180.7363\n",
      "Epoch 15/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 14376.2510 - val_loss: 15543.8525\n",
      "Epoch 16/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 15086.6063 - val_loss: 15354.2549\n",
      "Epoch 17/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 14198.8083 - val_loss: 15427.5625\n",
      "Epoch 18/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 14974.7762 - val_loss: 15111.7207\n",
      "Epoch 19/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 15193.5456 - val_loss: 16196.6992\n",
      "Epoch 20/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 14549.3872 - val_loss: 16112.4873\n",
      "Epoch 21/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 13606.3038 - val_loss: 17526.9277\n",
      "Epoch 22/300\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 15609.7097 - val_loss: 15275.7725\n",
      "Epoch 23/300\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 16111.7179 - val_loss: 15139.4072\n",
      "Epoch 24/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 14019.4707 - val_loss: 15609.0225\n",
      "Epoch 25/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 14921.2134 - val_loss: 15557.7812\n",
      "Epoch 26/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 14870.1476 - val_loss: 15701.7139\n",
      "Epoch 27/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 13965.9646 - val_loss: 15241.5400\n",
      "Epoch 28/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 15135.3344 - val_loss: 15509.7461\n",
      "Epoch 29/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 15251.7729 - val_loss: 17028.6191\n",
      "Epoch 30/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 14205.2409 - val_loss: 15059.2363\n",
      "Epoch 31/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 14021.2337 - val_loss: 15217.3857\n",
      "Epoch 32/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 15265.8565 - val_loss: 20069.3262\n",
      "Epoch 33/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 17846.0206 - val_loss: 18191.2891\n",
      "Epoch 34/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 20160.8027 - val_loss: 16534.7598\n",
      "Epoch 35/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 16093.2741 - val_loss: 15107.8096\n",
      "Epoch 36/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 13623.2060 - val_loss: 15828.4395\n",
      "Epoch 37/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 14650.0908 - val_loss: 15627.8350\n",
      "Epoch 38/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 14100.6195 - val_loss: 15297.0303\n",
      "Epoch 39/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 14824.8851 - val_loss: 15032.8994\n",
      "Epoch 40/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 14005.2591 - val_loss: 15025.1514\n",
      "Epoch 41/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 14399.7528 - val_loss: 15618.7588\n",
      "Epoch 42/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 15620.7073 - val_loss: 15215.2773\n",
      "Epoch 43/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 15401.7305 - val_loss: 16125.0547\n",
      "Epoch 44/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 15207.3231 - val_loss: 15231.7012\n",
      "Epoch 45/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 15694.8485 - val_loss: 15750.0732\n",
      "Epoch 46/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 14898.6406 - val_loss: 15213.7158\n",
      "Epoch 47/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 14435.7989 - val_loss: 17695.2793\n",
      "Epoch 48/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 16431.2158 - val_loss: 20686.7363\n",
      "Epoch 49/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 16241.7411 - val_loss: 15286.1680\n",
      "Epoch 50/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 16975.1166 - val_loss: 22513.7363\n",
      "Epoch 51/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18611.2211 - val_loss: 15059.9707\n",
      "Epoch 52/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 15299.0694 - val_loss: 16551.8965\n",
      "Epoch 53/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 15744.1267 - val_loss: 15811.0977\n",
      "Epoch 54/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 15731.9769 - val_loss: 15079.3496\n",
      "Epoch 55/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 16536.9474 - val_loss: 33589.9883\n",
      "Epoch 56/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 20312.9711 - val_loss: 15783.2959\n",
      "Epoch 57/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 15051.6557 - val_loss: 18874.6738\n",
      "Epoch 58/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 20336.6935 - val_loss: 15280.6055\n",
      "Epoch 59/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 15408.6170 - val_loss: 16338.4727\n",
      "Epoch 60/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 15938.4156 - val_loss: 21229.7949\n",
      "Epoch 61/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18775.9344 - val_loss: 20302.0879\n",
      "Epoch 62/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 16806.2509 - val_loss: 15351.2119\n",
      "Epoch 63/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 16983.6357 - val_loss: 16961.3359\n",
      "Epoch 64/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 16987.5500 - val_loss: 22406.7441\n",
      "Epoch 65/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 17442.5472 - val_loss: 18305.7578\n",
      "Epoch 66/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 17848.1369 - val_loss: 19066.4180\n",
      "Epoch 67/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 19440.1140 - val_loss: 40535.5508\n",
      "Epoch 68/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 28417.6001 - val_loss: 37602.5430\n",
      "Epoch 69/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 23360.2240 - val_loss: 15090.9873\n",
      "Epoch 70/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 15889.1926 - val_loss: 17914.9961\n",
      "Epoch 71/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 17398.6554 - val_loss: 15134.8682\n",
      "Epoch 72/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 20256.1611 - val_loss: 15243.0840\n",
      "Epoch 73/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 14788.8052 - val_loss: 17225.6426\n",
      "Epoch 74/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 17720.7914 - val_loss: 19054.8535\n",
      "Epoch 75/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 18622.8314 - val_loss: 16300.3896\n",
      "Epoch 76/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 49ms/step - loss: 17643.3873 - val_loss: 19971.8828\n",
      "Epoch 77/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 19759.1410 - val_loss: 19479.4863\n",
      "Epoch 78/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 16971.5803 - val_loss: 15382.4463\n",
      "Epoch 79/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 16111.6707 - val_loss: 19411.0449\n",
      "Epoch 80/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 17270.8690 - val_loss: 16864.2461\n",
      "Epoch 81/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 18367.0118 - val_loss: 16265.3701\n",
      "Epoch 82/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 15760.1839 - val_loss: 15571.4199\n",
      "Epoch 83/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 18258.3380 - val_loss: 16480.2227\n",
      "Epoch 84/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 15999.3583 - val_loss: 15248.1270\n",
      "Epoch 85/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 16056.3347 - val_loss: 44008.7578\n",
      "Epoch 86/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 24551.4702 - val_loss: 17259.7754\n",
      "Epoch 87/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 20235.9396 - val_loss: 16793.4941\n",
      "Epoch 88/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 17906.3855 - val_loss: 25879.4199\n",
      "Epoch 89/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 25217.2212 - val_loss: 15288.2891\n",
      "Epoch 90/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 15520.9914 - val_loss: 15876.9131\n",
      "Epoch 91/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18540.7741 - val_loss: 60423.9297\n",
      "Epoch 92/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 34440.3671 - val_loss: 66759.2656\n",
      "Epoch 93/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 39820.5356 - val_loss: 16038.5957\n",
      "Epoch 94/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 17142.0619 - val_loss: 20659.9004\n",
      "Epoch 95/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 58907.1703 - val_loss: 18582.7344\n",
      "Epoch 96/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 31300.3660 - val_loss: 18119.3555\n",
      "Epoch 97/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 22418.1988 - val_loss: 15824.8193\n",
      "Epoch 98/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 23556.5700 - val_loss: 58163.2695\n",
      "Epoch 99/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 36582.2334 - val_loss: 43655.0625\n",
      "Epoch 100/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 35720.4669 - val_loss: 79386.0391\n",
      "Epoch 101/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 55889.6553 - val_loss: 17769.2520\n",
      "Epoch 102/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 21886.2241 - val_loss: 16649.7051\n",
      "Epoch 103/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 25715.9153 - val_loss: 32605.4902\n",
      "Epoch 104/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 19872.1519 - val_loss: 33980.6172\n",
      "Epoch 105/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 67000.5871 - val_loss: 15284.3232\n",
      "Epoch 106/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 25968.7503 - val_loss: 133094.0000\n",
      "Epoch 107/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 88363.0924 - val_loss: 26587.8574\n",
      "Epoch 108/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 31760.1973 - val_loss: 19525.4082\n",
      "Epoch 109/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 31330.1749 - val_loss: 91818.1875\n",
      "Epoch 110/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 45752.8507 - val_loss: 68911.1406\n",
      "Epoch 111/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 33401.9435 - val_loss: 15009.8965\n",
      "Epoch 112/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 20474.9563 - val_loss: 26485.1445\n",
      "Epoch 113/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 26793.1451 - val_loss: 20471.8105\n",
      "Epoch 114/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 41232.9060 - val_loss: 15252.1650\n",
      "Epoch 115/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 17044.9898 - val_loss: 15770.8330\n",
      "Epoch 116/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 20867.6078 - val_loss: 121031.0703\n",
      "Epoch 117/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 78406.6286 - val_loss: 19533.0938\n",
      "Epoch 118/300\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 59223.9196 - val_loss: 25262.0352\n",
      "Epoch 119/300\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 18734.7590 - val_loss: 16994.7266\n",
      "Epoch 120/300\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 24345.0149 - val_loss: 23771.5195\n",
      "Epoch 121/300\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 95573.7856 - val_loss: 55410.8359\n",
      "Epoch 122/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 30148.8244 - val_loss: 29866.1855\n",
      "Epoch 123/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 46920.7476 - val_loss: 21446.5059\n",
      "Epoch 124/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 27475.7934 - val_loss: 21506.8711\n",
      "Epoch 125/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 22311.6433 - val_loss: 84795.5781\n",
      "Epoch 126/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 35841.8071 - val_loss: 17015.5625\n",
      "Epoch 127/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 19444.1764 - val_loss: 16295.8594\n",
      "Epoch 128/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 41689.7256 - val_loss: 15020.6533\n",
      "Epoch 129/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 17947.5388 - val_loss: 15467.3779\n",
      "Epoch 130/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 30836.8677 - val_loss: 17615.2617\n",
      "Epoch 131/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 43060.9798 - val_loss: 94552.4922\n",
      "Epoch 132/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 45622.4867 - val_loss: 15838.8330\n",
      "Epoch 133/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 16550.7778 - val_loss: 23203.0957\n",
      "Epoch 134/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 22956.6205 - val_loss: 15220.1035\n",
      "Epoch 135/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 40369.1476 - val_loss: 15725.9873\n",
      "Epoch 136/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18939.6852 - val_loss: 25050.3750\n",
      "Epoch 137/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 43016.2016 - val_loss: 75720.4766\n",
      "Epoch 138/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 72422.0148 - val_loss: 15649.8779\n",
      "Epoch 139/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 19264.5454 - val_loss: 23546.4922\n",
      "Epoch 140/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 43011.5050 - val_loss: 87233.9688\n",
      "Epoch 141/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 55385.7185 - val_loss: 16309.9932\n",
      "Epoch 142/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18218.3017 - val_loss: 74482.7500\n",
      "Epoch 143/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 52151.1512 - val_loss: 15457.6670\n",
      "Epoch 144/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 17420.5484 - val_loss: 16698.8965\n",
      "Epoch 145/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 16240.1160 - val_loss: 16673.6309\n",
      "Epoch 146/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 46865.8852 - val_loss: 421213.0312\n",
      "Epoch 147/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 120224.8739 - val_loss: 24008.4395\n",
      "Epoch 148/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 21056.5223 - val_loss: 17011.6875\n",
      "Epoch 149/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 19962.0281 - val_loss: 17314.7324\n",
      "Epoch 150/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 18471.5824 - val_loss: 24805.6621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 39811.1532 - val_loss: 45133.0703\n",
      "Epoch 152/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 28837.9650 - val_loss: 15740.2051\n",
      "Epoch 153/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 22967.9947 - val_loss: 19335.0488\n",
      "Epoch 154/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 30913.9192 - val_loss: 68723.5859\n",
      "Epoch 155/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 78801.3684 - val_loss: 23841.0234\n",
      "Epoch 156/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 46023.1908 - val_loss: 22840.2246\n",
      "Epoch 157/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18558.4980 - val_loss: 18555.3555\n",
      "Epoch 158/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18220.5182 - val_loss: 37865.6133\n",
      "Epoch 159/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 36865.3936 - val_loss: 178526.6250\n",
      "Epoch 160/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 85615.5642 - val_loss: 16604.9141\n",
      "Epoch 161/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 53059.5664 - val_loss: 16680.7520\n",
      "Epoch 162/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 26230.4929 - val_loss: 46579.2539\n",
      "Epoch 163/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 43621.8696 - val_loss: 17061.8340\n",
      "Epoch 164/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 78116.2496 - val_loss: 20084.6230\n",
      "Epoch 165/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 33056.2707 - val_loss: 50652.0469\n",
      "Epoch 166/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 64866.3259 - val_loss: 95857.1875\n",
      "Epoch 167/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 54942.0621 - val_loss: 18752.1680\n",
      "Epoch 168/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 25687.4192 - val_loss: 198733.5625\n",
      "Epoch 169/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 84569.4787 - val_loss: 15626.6650\n",
      "Epoch 170/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 35489.7412 - val_loss: 15279.3213\n",
      "Epoch 171/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 30327.0202 - val_loss: 30964.3730\n",
      "Epoch 172/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 19038.3063 - val_loss: 16975.2969\n",
      "Epoch 173/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 23733.5799 - val_loss: 17233.7988\n",
      "Epoch 174/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 17713.4524 - val_loss: 16222.0186\n",
      "Epoch 175/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 19266.9710 - val_loss: 15353.9219\n",
      "Epoch 176/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 15880.0570 - val_loss: 17164.5273\n",
      "Epoch 177/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 28181.4096 - val_loss: 37851.0703\n",
      "Epoch 178/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 38476.5527 - val_loss: 25322.6133\n",
      "Epoch 179/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 67371.7407 - val_loss: 77662.3438\n",
      "Epoch 180/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 66116.1558 - val_loss: 25460.2656\n",
      "Epoch 181/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 33062.5160 - val_loss: 16860.8262\n",
      "Epoch 182/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 30075.8147 - val_loss: 15233.8125\n",
      "Epoch 183/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 16601.4630 - val_loss: 24355.4863\n",
      "Epoch 184/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 36080.7847 - val_loss: 31795.9102\n",
      "Epoch 185/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 75576.6390 - val_loss: 366242.1250\n",
      "Epoch 186/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 238802.9654 - val_loss: 53877.7812\n",
      "Epoch 187/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 24949.3647 - val_loss: 19492.3730\n",
      "Epoch 188/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 17585.0442 - val_loss: 24411.4785\n",
      "Epoch 189/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 28434.9874 - val_loss: 32151.1484\n",
      "Epoch 190/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 31511.5183 - val_loss: 15492.7422\n",
      "Epoch 191/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 29335.7755 - val_loss: 15577.2822\n",
      "Epoch 192/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 25782.8201 - val_loss: 21566.7520\n",
      "Epoch 193/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 23232.0488 - val_loss: 22506.3926\n",
      "Epoch 194/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18637.3014 - val_loss: 24062.8223\n",
      "Epoch 195/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 43531.3777 - val_loss: 16101.3584\n",
      "Epoch 196/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 25144.7815 - val_loss: 15106.2490\n",
      "Epoch 197/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 22260.0883 - val_loss: 15130.2822\n",
      "Epoch 198/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 43518.9474 - val_loss: 79832.1250\n",
      "Epoch 199/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 106640.7023 - val_loss: 26453.2695\n",
      "Epoch 200/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 24210.7278 - val_loss: 15536.4629\n",
      "Epoch 201/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 31998.3483 - val_loss: 20185.4648\n",
      "Epoch 202/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 46255.2335 - val_loss: 45291.1250\n",
      "Epoch 203/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 35065.1314 - val_loss: 15743.1611\n",
      "Epoch 204/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 18720.2845 - val_loss: 23414.5078\n",
      "Epoch 205/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 21416.7227 - val_loss: 22062.7969\n",
      "Epoch 206/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 31256.6436 - val_loss: 25774.5508\n",
      "Epoch 207/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 19965.2203 - val_loss: 61752.1055\n",
      "Epoch 208/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 35092.2384 - val_loss: 455041.4375\n",
      "Epoch 209/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 283126.3292 - val_loss: 50278.6133\n",
      "Epoch 210/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 46665.5415 - val_loss: 19202.0664\n",
      "Epoch 211/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 69234.7610 - val_loss: 19631.4102\n",
      "Epoch 212/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 37708.8939 - val_loss: 15771.7529\n",
      "Epoch 213/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 23834.8136 - val_loss: 15531.5312\n",
      "Epoch 214/300\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 18561.5991 - val_loss: 26229.5684\n",
      "Epoch 215/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 29358.2053 - val_loss: 17689.3398\n",
      "Epoch 216/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 17925.9857 - val_loss: 17870.4609\n",
      "Epoch 217/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 19430.4015 - val_loss: 33375.9219\n",
      "Epoch 218/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 27277.6325 - val_loss: 36164.6562\n",
      "Epoch 219/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 52007.9621 - val_loss: 43326.0469\n",
      "Epoch 220/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 43636.5236 - val_loss: 16629.1035\n",
      "Epoch 221/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 49031.8937 - val_loss: 16788.9863\n",
      "Epoch 222/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 35302.1744 - val_loss: 22393.3496\n",
      "Epoch 223/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 18651.4782 - val_loss: 47152.3672\n",
      "Epoch 224/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 32601.1575 - val_loss: 15289.6943\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 51ms/step - loss: 25902.3950 - val_loss: 21896.8984\n",
      "Epoch 226/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 30319.8141 - val_loss: 17139.7773\n",
      "Epoch 227/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 17446.6110 - val_loss: 21902.7324\n",
      "Epoch 228/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 20894.0233 - val_loss: 84420.5391\n",
      "Epoch 229/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 48484.3991 - val_loss: 17183.1016\n",
      "Epoch 230/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 18033.9369 - val_loss: 67008.5625\n",
      "Epoch 231/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 37411.3312 - val_loss: 18076.5566\n",
      "Epoch 232/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 41083.1311 - val_loss: 23737.0879\n",
      "Epoch 233/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 20542.8546 - val_loss: 47267.1875\n",
      "Epoch 234/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 31518.0268 - val_loss: 28889.9531\n",
      "Epoch 235/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 27901.1601 - val_loss: 15014.0625\n",
      "Epoch 236/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 42747.2830 - val_loss: 16889.1289\n",
      "Epoch 237/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 26218.5386 - val_loss: 29055.9277\n",
      "Epoch 238/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 26833.5610 - val_loss: 20600.1738\n",
      "Epoch 239/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 24945.5758 - val_loss: 15743.1113\n",
      "Epoch 240/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 16841.3748 - val_loss: 19663.1836\n",
      "Epoch 241/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 19053.4278 - val_loss: 25888.1406\n",
      "Epoch 242/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 50520.8579 - val_loss: 47738.6914\n",
      "Epoch 243/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 41785.6200 - val_loss: 25031.3516\n",
      "Epoch 244/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 67036.3882 - val_loss: 617049.2500\n",
      "Epoch 245/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 278200.8499 - val_loss: 46444.0742\n",
      "Epoch 246/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 42537.6314 - val_loss: 107917.7969\n",
      "Epoch 247/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 47522.5298 - val_loss: 35034.9297\n",
      "Epoch 248/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 29411.6452 - val_loss: 41875.3164\n",
      "Epoch 249/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 21245.4473 - val_loss: 25277.8164\n",
      "Epoch 250/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 20295.0433 - val_loss: 19792.4258\n",
      "Epoch 251/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 18528.3221 - val_loss: 16154.5078\n",
      "Epoch 252/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 20216.8464 - val_loss: 158311.6875\n",
      "Epoch 253/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 54198.7321 - val_loss: 15237.7871\n",
      "Epoch 254/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 23293.6952 - val_loss: 16484.0137\n",
      "Epoch 255/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 15042.9018 - val_loss: 17745.1367\n",
      "Epoch 256/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 22589.7373 - val_loss: 25661.3887\n",
      "Epoch 257/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 27465.3811 - val_loss: 15108.1426\n",
      "Epoch 258/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 25267.7093 - val_loss: 16692.7285\n",
      "Epoch 259/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 18798.7285 - val_loss: 24905.4844\n",
      "Epoch 260/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 21171.5457 - val_loss: 15023.6025\n",
      "Epoch 261/300\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 35253.6136 - val_loss: 21704.9062\n",
      "Epoch 262/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 26841.2024 - val_loss: 47755.2656\n",
      "Epoch 263/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 34022.7510 - val_loss: 15346.4355\n",
      "Epoch 264/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 19968.5844 - val_loss: 69808.6562\n",
      "Epoch 265/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 56547.1130 - val_loss: 17383.7871\n",
      "Epoch 266/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 30802.4196 - val_loss: 19859.7480\n",
      "Epoch 267/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 21149.6597 - val_loss: 29282.0176\n",
      "Epoch 268/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 30240.4768 - val_loss: 15413.6836\n",
      "Epoch 269/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 36950.4457 - val_loss: 16144.7588\n",
      "Epoch 270/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 21956.1651 - val_loss: 15107.5586\n",
      "Epoch 271/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 49520.3186 - val_loss: 74798.7344\n",
      "Epoch 272/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 37586.4806 - val_loss: 45511.6367\n",
      "Epoch 273/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 34826.5817 - val_loss: 16458.0156\n",
      "Epoch 274/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 24929.3820 - val_loss: 19636.9492\n",
      "Epoch 275/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 50334.2085 - val_loss: 15537.8008\n",
      "Epoch 276/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 20395.8351 - val_loss: 21088.3477\n",
      "Epoch 277/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18830.4384 - val_loss: 16007.2314\n",
      "Epoch 278/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 30565.9023 - val_loss: 25433.6660\n",
      "Epoch 279/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 22418.8820 - val_loss: 47359.9375\n",
      "Epoch 280/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 66613.1574 - val_loss: 37928.8398\n",
      "Epoch 281/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 74835.5010 - val_loss: 153765.6562\n",
      "Epoch 282/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 85834.5071 - val_loss: 15218.8770\n",
      "Epoch 283/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 17964.0745 - val_loss: 16399.7500\n",
      "Epoch 284/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 17886.1658 - val_loss: 20707.7031\n",
      "Epoch 285/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 18624.4014 - val_loss: 51096.9336\n",
      "Epoch 286/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 26222.9664 - val_loss: 15145.4893\n",
      "Epoch 287/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 31726.0209 - val_loss: 53254.8203\n",
      "Epoch 288/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 30117.9606 - val_loss: 60870.1797\n",
      "Epoch 289/300\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 66136.8569 - val_loss: 16432.4961\n",
      "Epoch 290/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 21221.2784 - val_loss: 15213.6484\n",
      "Epoch 291/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 34065.0412 - val_loss: 115969.8516\n",
      "Epoch 292/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 88987.0437 - val_loss: 20935.5137\n",
      "Epoch 293/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 33192.1434 - val_loss: 15550.4160\n",
      "Epoch 294/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 40349.3202 - val_loss: 104335.3984\n",
      "Epoch 295/300\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 51577.1321 - val_loss: 15162.1533\n",
      "Epoch 296/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 20239.0549 - val_loss: 18126.8359\n",
      "Epoch 297/300\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 18576.4027 - val_loss: 15921.7998\n",
      "Epoch 298/300\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 36893.7502 - val_loss: 345484.0312\n",
      "Epoch 299/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 49ms/step - loss: 138874.4690 - val_loss: 15411.3545\n",
      "Epoch 300/300\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 27487.2129 - val_loss: 41673.3320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x182ca279908>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y = y_train,validation_data=(x_test,y_test),epochs=300, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Uz7bsYSGvaMP"
   },
   "outputs": [],
   "source": [
    "loss_value = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "xur6xAVnvfSm",
    "outputId": "55406ad5-98e5-4304-a652-bd8ab7d29de5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x182ce060888>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_value.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIrrvcE5vn6B",
    "outputId": "6b2ff81b-bf8b-4170-f817-fac2b58b8f89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9428.455],\n",
       "       [ 6689.719],\n",
       "       [ 6439.988],\n",
       "       ...,\n",
       "       [ 8275.099],\n",
       "       [27480.893],\n",
       "       [ 6434.849]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_que = model.predict(x_test)\n",
    "predict_que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Er76Kv2Evo04",
    "outputId": "ac9fd08c-2c21-4bb8-f41a-42b2c06242c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142.56522966872788"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,predict_que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "4LqqFm-mvuSX",
    "outputId": "1a957f81-9c59-4320-9cda-2e7e9365267c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x182ca301408>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,predict_que)\n",
    "plt.plot(y_test,y_test,\"g-*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAhjpWu9vv4e",
    "outputId": "14cb9edd-7bbf-469c-ff8e-150067fefa7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var1(t-1)    34150.23\n",
       "var1(t)      33906.57\n",
       "Name: 32901, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[32900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KxjJ_-SGvzvr",
    "outputId": "55c75bb3-c77f-4589-f53d-74d5c53eb400"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var1(t-1)    34150.23\n",
       "Name: 32901, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prices = data.drop(\"var1(t)\",axis=1).iloc[32900]\n",
    "new_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RI5Y8apRv2A5",
    "outputId": "f1fca4b4-2153-49b4-86d2-34d7ac869f89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68983373]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prices = scaler.transform(new_prices.values.reshape(-1,1))\n",
    "new_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9y9PWHhv20e",
    "outputId": "f0791ffe-826d-439a-942e-e528a9184972"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34687.02]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_yUwjf4v_-X",
    "outputId": "acaef4e9-9798-4894-c5f4-e489b30809cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39489.82]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_price = [[38875]]\n",
    "current_price = scaler.transform(current_price)\n",
    "model.predict(current_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kF66QBaewGzX",
    "outputId": "9486f2dc-d581-4f24-af51-2f924c99412d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4537.1704],\n",
       "       [ 4543.711 ],\n",
       "       [ 4552.811 ],\n",
       "       ...,\n",
       "       [47987.457 ],\n",
       "       [47590.56  ],\n",
       "       [47166.76  ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_predict_que =scaler.fit_transform(x)\n",
    "predicted_que = model.predict(scaled_predict_que)\n",
    "predicted_que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-zkXAStwIed",
    "outputId": "be31e6a6-8f07-4a34-902c-4cc1de696f5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dogru bilinen sayisi ->3433\n",
      "Yanlis bilinen sayisi ->3204\n",
      "Accuracy->0.5172517703781829\n"
     ]
    }
   ],
   "source": [
    "values_correct = 0\n",
    "values_incorrect = 0\n",
    "for a in range(6637):\n",
    "  if y_evolution[a] > x_evolution[a] and predicted_que[a] > x_evolution[a]:\n",
    "    values_correct += 1\n",
    "  elif y_evolution[a] < x_evolution[a] and predicted_que[a] < x_evolution[a]:\n",
    "    values_correct += 1\n",
    "  else:\n",
    "    values_incorrect += 1\n",
    "print(\"Dogru bilinen sayisi ->{}\".format(values_correct))\n",
    "print(\"Yanlis bilinen sayisi ->{}\".format(values_incorrect))\n",
    "print(\"Accuracy->{}\".format(float(values_correct)/6637))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6arNXOHH4MvA",
    "outputId": "f4079785-1fea-48ad-93cc-da880701c085"
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "import weakref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle weakref objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-f573f57429d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpkl_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"pickle_model.pkl\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkl_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't pickle weakref objects"
     ]
    }
   ],
   "source": [
    "pkl_filename = \"pickle_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "time series - single variate 1H",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
